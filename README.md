# DatamartAPI
API developed in Python using Parquet files as data resources for review, FastApi Framework, unit testing, and CI/CD integration.

# ğŸš€ Sales Datamart API

API RESTful para consulta y anÃ¡lisis de datos de ventas, desarrollada con FastAPI y diseÃ±ada para procesar grandes volÃºmenes de datos desde archivos Parquet.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/Tests-Passing-success.svg)](tests/)
[![Coverage](https://img.shields.io/badge/Coverage-95%25-brightgreen.svg)](htmlcov/)

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Arquitectura](#-arquitectura)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
  - [InstalaciÃ³n Local](#instalaciÃ³n-local)
  - [InstalaciÃ³n con Docker](#instalaciÃ³n-con-docker)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso](#-uso)
- [Endpoints Disponibles](#-endpoints-disponibles)
- [Testing](#-testing)
- [Docker](#-docker)
- [CI/CD](#-cicd)
- [Deployment](#-deployment)
- [Autor](#-autor)

---

## ğŸ“– DescripciÃ³n

**Sales Datamart API** es un microservicio diseÃ±ado para proporcionar acceso eficiente y seguro a datos analÃ­ticos de ventas almacenados en formato Parquet. La API permite realizar consultas complejas, agregaciones y anÃ¡lisis de datos de ventas por diferentes dimensiones (empleados, productos, tiendas).

### Casos de Uso

- ğŸ“Š **AnÃ¡lisis de DesempeÃ±o**: Evaluar ventas por empleado, producto o tienda
- ğŸ“ˆ **Reportes Ejecutivos**: Generar mÃ©tricas de totales y promedios
- ğŸ” **AnÃ¡lisis Temporal**: Consultar ventas en periodos especÃ­ficos
- ğŸ“‰ **IdentificaciÃ³n de Tendencias**: Detectar patrones de venta
- ğŸ† **KPIs**: Calcular indicadores clave de rendimiento

---

## âœ¨ CaracterÃ­sticas

### Funcionalidades Principales

- âœ… **Consultas por Periodo**
  - Ventas por empleado en rango de fechas
  - Ventas por producto en rango de fechas
  - Ventas por tienda en rango de fechas

- âœ… **Agregaciones y EstadÃ­sticas**
  - Total y promedio de ventas por empleado
  - Total y promedio de ventas por producto
  - Total y promedio de ventas por tienda

### CaracterÃ­sticas TÃ©cnicas

- ğŸš€ **Alto Rendimiento**: Procesamiento eficiente de grandes volÃºmenes de datos
- ğŸ“Š **Datos en Parquet**: Lectura optimizada de archivos columnares
- ğŸ” **Seguridad**: AutenticaciÃ³n JWT (preparado para implementaciÃ³n)
- âœ… **ValidaciÃ³n**: ValidaciÃ³n automÃ¡tica de parÃ¡metros con Pydantic
- ğŸ“ **DocumentaciÃ³n**: Swagger UI y ReDoc integrados
- ğŸ³ **Dockerizado**: FÃ¡cil despliegue con Docker y Docker Compose
- ğŸ§ª **Testing**: Cobertura >95% con tests unitarios
- ğŸ”„ **CI/CD**: Pipeline automatizado con GitHub Actions
- ğŸ“ˆ **Logging**: Sistema robusto de logs para debugging
- ğŸ¥ **Health Checks**: Endpoints de monitoreo

---

## ğŸ›  TecnologÃ­as

### Backend

- **[FastAPI](https://fastapi.tiangolo.com/)** 0.104+ - Framework web moderno y rÃ¡pido
- **[Python](https://www.python.org/)** 3.11+ - Lenguaje de programaciÃ³n
- **[Pydantic](https://docs.pydantic.dev/)** 2.5+ - ValidaciÃ³n de datos
- **[Pandas](https://pandas.pydata.org/)** 2.1+ - Procesamiento de datos
- **[PyArrow](https://arrow.apache.org/docs/python/)** 14.0+ - Lectura de archivos Parquet
- **[Uvicorn](https://www.uvicorn.org/)** - Servidor ASGI

### Testing

- **[Pytest](https://docs.pytest.org/)** 7.4+ - Framework de testing
- **[Pytest-cov](https://pytest-cov.readthedocs.io/)** - Cobertura de cÃ³digo
- **[Pytest-asyncio](https://pytest-asyncio.readthedocs.io/)** - Tests asÃ­ncronos
- **[Pytest-mock](https://pytest-mock.readthedocs.io/)** - Mocking

### DevOps

- **[Docker](https://www.docker.com/)** - ContainerizaciÃ³n
- **[Docker Compose](https://docs.docker.com/compose/)** - OrquestaciÃ³n de contenedores
- **[GitHub Actions](https://github.com/features/actions)** - CI/CD

### Code Quality

- **[Black](https://black.readthedocs.io/)** - Formateo de cÃ³digo
- **[Flake8](https://flake8.pycqa.org/)** - Linting
- **[isort](https://pycqa.github.io/isort/)** - Ordenamiento de imports
- **[Bandit](https://bandit.readthedocs.io/)** - AnÃ¡lisis de seguridad

---

## ğŸ— Arquitectura

### Arquitectura de Alto Nivel
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente/UI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      API Routes Layer       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Business Logic Layer      â”‚   â”‚
â”‚  â”‚  (DatamartService)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Data Access Layer        â”‚   â”‚
â”‚  â”‚    (Pandas + PyArrow)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Parquet Filesâ”‚
      â”‚   (Datamart)  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Estructura de Capas

1. **API Layer** (`app/api/routes/`)
   - Manejo de requests/responses
   - ValidaciÃ³n de parÃ¡metros
   - DocumentaciÃ³n de endpoints

2. **Business Logic Layer** (`app/services/`)
   - LÃ³gica de negocio
   - CÃ¡lculos y agregaciones
   - TransformaciÃ³n de datos

3. **Data Access Layer** (`app/services/datamart.py`)
   - Lectura de archivos Parquet
   - Filtrado y consultas
   - OptimizaciÃ³n de queries

4. **Models Layer** (`app/models/`)
   - Modelos Pydantic
   - ValidaciÃ³n de datos
   - SerializaciÃ³n

---

## ğŸ“‹ Requisitos Previos

### OpciÃ³n 1: InstalaciÃ³n Local

- Python 3.11 o superior
- pip (gestor de paquetes de Python)
- Archivos .parquet del datamart

### OpciÃ³n 2: InstalaciÃ³n con Docker

- Docker 20.10 o superior
- Docker Compose 2.0 o superior
- Archivos .parquet del datamart

---

## ğŸš€ InstalaciÃ³n

### InstalaciÃ³n Local

#### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/sales-datamart-api.git
cd sales-datamart-api
```

#### 2. Crear entorno virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

#### 4. Configurar variables de entorno
```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar .env con tus valores
# En Windows: notepad .env
# En Linux/Mac: nano .env
```

#### 5. Preparar el datamart
```bash
# Crear carpeta para archivos parquet
mkdir datamart

# Copiar tus archivos .parquet a la carpeta datamart/
# Los archivos deben tener la estructura esperada
```

#### 6. Iniciar la aplicaciÃ³n
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### 7. Verificar instalaciÃ³n
```bash
# Abrir navegador en:
# http://localhost:8000/docs
# O verificar con curl:
curl http://localhost:8000/health
```

---

### InstalaciÃ³n con Docker

#### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/sales-datamart-api.git
cd sales-datamart-api
```

#### 2. Preparar el datamart
```bash
# Crear carpeta y copiar archivos .parquet
mkdir datamart
# Copiar tus archivos .parquet a datamart/
```

#### 3. Configurar variables de entorno
```bash
cp .env.example .env
# Editar .env si es necesario
```

#### 4. Iniciar con Docker Compose
```bash
# Usando script (recomendado)
chmod +x scripts/*.sh
./scripts/start.sh

# O manualmente
docker-compose up -d
```

#### 5. Verificar instalaciÃ³n
```bash
# Ver logs
docker-compose logs -f api

# Verificar health
curl http://localhost:8000/health

# Abrir documentaciÃ³n
# http://localhost:8000/docs
```

---

## âš™ ConfiguraciÃ³n

### Variables de Entorno

El archivo `.env` debe contener las siguientes variables:
```bash
# Ruta al directorio con archivos .parquet
# Local: ./datamart
# Docker: /datamart (no cambiar)
DATAMART_PATH=./datamart

# Modo debug (True/False)
DEBUG=False

# Nivel de logging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Seguridad JWT (para implementaciÃ³n futura)
SECRET_KEY=tu-secret-key-super-segura-cambiar
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS (orÃ­genes permitidos, separados por coma)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
```

### Generar SECRET_KEY segura
```bash
# Linux/Mac
openssl rand -hex 32

# Python
python -c "import secrets; print(secrets.token_hex(32))"
```

---

## ğŸ“š Uso

### Acceder a la DocumentaciÃ³n

Una vez iniciada la aplicaciÃ³n, puedes acceder a:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/api/v1/openapi.json

### Ejemplo de Uso con cURL

#### 1. Health Check
```bash
curl http://localhost:8000/health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "service": "Sales Datamart API",
  "version": "1.0.0",
  "datamart_loaded": true,
  "records_count": 323326
}
```

#### 2. Consultar ventas por empleado
```bash
curl "http://localhost:8000/api/v1/sales/by-employee?key_employee=1%7C343&date_start=2023-11-01&date_end=2023-11-30"
```

**Respuesta:**
```json
{
  "success": true,
  "key_employee": "1|343",
  "date_start": "2023-11-01",
  "date_end": "2023-11-30",
  "total_amount": -24873.95,
  "total_quantity": -4,
  "records_count": 1,
  "sales": [
    {
      "date": "2023-11-02",
      "amount": -24873.95,
      "quantity": -4,
      "ticket_id": "N01-00000385",
      "product": "1|44733",
      "store": "1|023"
    }
  ]
}
```

### Ejemplo de Uso con Python
```python
import requests

# Base URL
BASE_URL = "http://localhost:8000"

# 1. Health check
health = requests.get(f"{BASE_URL}/health")
print(health.json())

# 2. Consultar ventas por empleado
response = requests.get(
    f"{BASE_URL}/api/v1/sales/by-employee",
    params={
        "key_employee": "1|343",
        "date_start": "2023-11-01",
        "date_end": "2023-11-30"
    }
)
data = response.json()
print(f"Total ventas: ${data['total_amount']:,.2f}")
print(f"Registros: {data['records_count']}")

# 3. Resumen de todos los empleados
summary = requests.get(f"{BASE_URL}/api/v1/sales/employee-summary")
print(summary.json())
```

### Ejemplo de Uso con JavaScript/Fetch
```javascript
// Base URL
const BASE_URL = 'http://localhost:8000';

// Consultar ventas por producto
async function getSalesByProduct() {
  const response = await fetch(
    `${BASE_URL}/api/v1/sales/by-product?` +
    `key_product=1|44733&` +
    `date_start=2023-11-01&` +
    `date_end=2023-11-30`
  );
  
  const data = await response.json();
  console.log('Total ventas:', data.total_amount);
  console.log('Cantidad:', data.total_quantity);
}

getSalesByProduct();
```

---

## ğŸ”Œ Endpoints Disponibles

### ğŸ¥ Health & Status

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/` | InformaciÃ³n bÃ¡sica del API |
| GET | `/health` | Estado del servicio y datamart |

### ğŸ“… Consultas por Periodo

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/api/v1/sales/by-employee` | Ventas por empleado en periodo |
| GET | `/api/v1/sales/by-product` | Ventas por producto en periodo |
| GET | `/api/v1/sales/by-store` | Ventas por tienda en periodo |

**ParÃ¡metros comunes:**
- `key_employee/key_product/key_store`: ID de la entidad (formato: "1|343")
- `date_start`: Fecha inicio (formato: YYYY-MM-DD)
- `date_end`: Fecha fin (formato: YYYY-MM-DD)

### ğŸ“Š Agregaciones y ResÃºmenes

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/api/v1/sales/employee-summary` | Total y promedio por empleado |
| GET | `/api/v1/sales/product-summary` | Total y promedio por producto |
| GET | `/api/v1/sales/store-summary` | Total y promedio por tienda |

**ParÃ¡metros opcionales:**
- `key_employee/key_product/key_store`: ID de la entidad (opcional)
  - Si se proporciona: resumen de esa entidad especÃ­fica
  - Si NO se proporciona: resumen de todas las entidades

### ğŸ“– DocumentaciÃ³n

| Endpoint | DescripciÃ³n |
|----------|-------------|
| `/docs` | DocumentaciÃ³n Swagger UI (interactiva) |
| `/redoc` | DocumentaciÃ³n ReDoc (alternativa) |
| `/api/v1/openapi.json` | Esquema OpenAPI en JSON |

---

## ğŸ§ª Testing

### Ejecutar Tests Localmente
```bash
# Todos los tests
pytest

# Solo unit tests
pytest tests/unit/ -v

# Con cobertura
pytest tests/unit/ --cov=app --cov-report=html --cov-report=term-missing

# Tests especÃ­ficos
pytest tests/unit/test_datamart_service.py -v

# Tests con marca especÃ­fica
pytest -m unit -v

# Ver reporte de cobertura HTML
# Abrir: htmlcov/index.html
```

### Ejecutar Tests en Docker
```bash
# Usando script
./scripts/test.sh

# Manualmente
docker-compose run --rm api pytest tests/unit/ -v --cov=app
```

### Estructura de Tests
```
tests/
â”œâ”€â”€ conftest.py              # Fixtures compartidas
â”œâ”€â”€ unit/                    # Tests unitarios (95% cobertura)
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_datamart_service.py
â”‚   â”œâ”€â”€ test_datamart_service_product.py
â”‚   â”œâ”€â”€ test_datamart_service_summary.py
â”‚   â”œâ”€â”€ test_datamart_service_product_summary.py
â”‚   â”œâ”€â”€ test_datamart_service_store_summary.py
â”‚   â”œâ”€â”€ test_sales_endpoint.py
â”‚   â”œâ”€â”€ test_sales_endpoint_product.py
â”‚   â”œâ”€â”€ test_sales_endpoint_summary.py
â”‚   â”œâ”€â”€ test_sales_endpoint_product_summary.py
â”‚   â””â”€â”€ test_sales_endpoint_store_summary.py
â””â”€â”€ fixtures/
    â””â”€â”€ sample_datamart.parquet
```

### MÃ©tricas de Cobertura

- **Cobertura Total**: >95%
- **Cobertura por MÃ³dulo**:
  - `app/config.py`: 92%
  - `app/services/datamart.py`: 96%
  - `app/api/routes/sales.py`: 94%
  - `app/models/responses.py`: 100%

---

## ğŸ³ Docker

### Comandos Principales

#### Iniciar la AplicaciÃ³n
```bash
# ProducciÃ³n
./scripts/start.sh
# O manualmente:
docker-compose up -d

# Desarrollo (con hot-reload)
./scripts/start-dev.sh
# O manualmente:
docker-compose -f docker-compose.dev.yml up
```

#### Ver Logs
```bash
# Ver logs en tiempo real
docker-compose logs -f api

# Ver Ãºltimas 100 lÃ­neas
docker-compose logs --tail=100 api

# Ver logs de un periodo especÃ­fico
docker-compose logs --since 1h api
```

#### Detener la AplicaciÃ³n
```bash
# Detener contenedores
./scripts/stop.sh
# O manualmente:
docker-compose down

# Detener y eliminar volÃºmenes
docker-compose down -v
```

#### Reconstruir la Imagen
```bash
# Reconstruir sin cache
docker-compose build --no-cache

# Reconstruir y reiniciar
docker-compose up -d --build
```

#### Ejecutar Tests en Docker
```bash
./scripts/test.sh
```

#### Acceder al Contenedor
```bash
# Bash interactivo
docker-compose exec api bash

# Ejecutar comando especÃ­fico
docker-compose exec api python -c "from app.main import app; print('OK')"
```

#### Ver Estado de Contenedores
```bash
# Listar contenedores
docker-compose ps

# Ver uso de recursos
docker stats

# Inspeccionar contenedor
docker inspect sales-datamart-api
```

#### Limpiar Todo (Cuidado!)
```bash
# Detener y eliminar todo
docker-compose down -v --rmi all

# Limpiar sistema Docker completo
docker system prune -a --volumes
```

### Estructura de VolÃºmenes
```
Proyecto/
â”œâ”€â”€ datamart/          # â†’ Montado en /datamart (read-only)
â”œâ”€â”€ logs/             # â†’ Montado en /app/logs
â””â”€â”€ app/              # â†’ CÃ³digo de la aplicaciÃ³n
```

### Variables de Entorno en Docker

En Docker, las variables de entorno se configuran en `docker-compose.yml`:
```yaml
environment:
  - DATAMART_PATH=/datamart  # Siempre /datamart en Docker
  - DEBUG=False
  - LOG_LEVEL=INFO
```

### Troubleshooting Docker

#### La API no encuentra los archivos .parquet
```bash
# Verificar que la carpeta existe
ls -la datamart/

# Verificar montaje del volumen
docker-compose exec api ls -la /datamart/

# Verificar permisos
chmod -R 755 datamart/
```

#### Error de permisos
```bash
# Dar permisos correctos
chmod -R 755 datamart/
chown -R $USER:$USER datamart/

# Reconstruir imagen
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

#### Puerto 8000 ya estÃ¡ en uso
```bash
# Ver quÃ© proceso usa el puerto
lsof -i :8000

# Cambiar puerto en docker-compose.yml
ports:
  - "8001:8000"  # Cambiar 8000 a 8001
```

#### Reiniciar completamente
```bash
docker-compose down -v
docker-compose build --no-cache
docker-compose up -d
docker-compose logs -f api
```

---

## ğŸ”„ CI/CD

### Pipeline de GitHub Actions

El proyecto incluye un pipeline completo de CI/CD que se ejecuta automÃ¡ticamente en cada push o pull request.

### Workflow Principal

**Archivo**: `.github/workflows/ci-cd.yml`

#### Jobs del Pipeline

1. **ğŸ” Lint & Code Quality**
   - Black (formateo)
   - Flake8 (linting)
   - isort (imports)
   - Bandit (seguridad)
   - Safety (vulnerabilidades)

2. **ğŸ§ª Unit Tests**
   - EjecuciÃ³n de pytest
   - Cobertura de cÃ³digo (>80%)
   - Upload a Codecov
   - GeneraciÃ³n de reportes

3. **ğŸ³ Build Docker Image**
   - Build de imagen Docker
   - Test de imagen
   - Cache de capas

4. **ğŸ”’ Security Scan**
   - Trivy vulnerability scanner
   - Upload a GitHub Security

5. **ğŸš€ Deploy to Staging** (branch: develop)
   - Build y push a Docker Hub
   - Deploy automÃ¡tico a staging

6. **ğŸš€ Deploy to Production** (branch: main)
   - Build y push a Docker Hub
   - Deploy automÃ¡tico a producciÃ³n

### Flujo de Trabajo
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  git push    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lint & Test  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Build Docker â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Security Scan â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚
       â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Staging    â”‚  â”‚  Production  â”‚
â”‚  (develop)   â”‚  â”‚    (main)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configurar GitHub Actions

#### 1. Secrets Necesarios

Ve a: **Settings â†’ Secrets and variables â†’ Actions**

Agregar los siguientes secrets:

| Secret | DescripciÃ³n | Ejemplo |
|--------|-------------|---------|
| `DOCKER_USERNAME` | Usuario de Docker Hub | `danilo-herazo` |
| `DOCKER_PASSWORD` | Password/Token de Docker Hub | `dckr_pat_xxx` |
| `STAGING_SERVER_HOST` | IP del servidor staging | `192.168.1.100` |
| `STAGING_SERVER_SSH_KEY` | SSH private key staging | `-----BEGIN RSA PRIVATE KEY-----` |
| `PROD_SERVER_HOST` | IP del servidor producciÃ³n | `192.168.1.200` |
| `PROD_SERVER_SSH_KEY` | SSH private key producciÃ³n | `-----BEGIN RSA PRIVATE KEY-----` |

#### 2. Crear Token de Docker Hub
```bash
# 1. Ir a: https://hub.docker.com/settings/security
# 2. Click en "New Access Token"
# 3. Nombre: "GitHub Actions"
# 4. Permisos: Read, Write, Delete
# 5. Copiar el token generado
```

#### 3. Configurar SSH Keys
```bash
# Generar par de claves SSH
ssh-keygen -t rsa -b 4096 -C "deploy@sales-api"

# Copiar clave pÃºblica al servidor
ssh-copy-id user@server-ip

# Copiar clave privada a GitHub Secrets
cat ~/.ssh/id_rsa
# Pegar contenido completo en GitHub Secret
```

### Monitoreo del Pipeline

#### Ver estado del pipeline
```bash
# En la interfaz de GitHub:
# Repository â†’ Actions â†’ Ver workflows

# O con GitHub CLI:
gh run list
gh run view <run-id>
gh run watch
```

#### Badges de Estado

Agregar al README.md:
```markdown
![CI/CD](https://github.com/tu-usuario/sales-datamart-api/workflows/CI%2FCD%20Pipeline/badge.svg)
![Tests](https://github.com/tu-usuario/sales-datamart-api/workflows/Test%20Pull%20Request/badge.svg)
```

---

## ğŸš€ Deployment

### Ambientes

#### 1. Development (Local)
```bash
# Desarrollo local sin Docker
uvicorn app.main:app --reload

# Desarrollo local con Docker
docker-compose -f docker-compose.dev.yml up
```

- **URL**: http://localhost:8000
- **Debug**: Activado
- **Hot-reload**: SÃ­
- **Logs**: Verbose

#### 2. Staging (AutomÃ¡tico)

- **Branch**: `develop`
- **URL**: https://staging-api.example.com
- **Deploy**: AutomÃ¡tico via GitHub Actions
- **PropÃ³sito**: Testing antes de producciÃ³n

#### 3. Production (AutomÃ¡tico)

- **Branch**: `main`
- **URL**: https://api.example.com
- **Deploy**: AutomÃ¡tico via GitHub Actions
- **PropÃ³sito**: Ambiente de producciÃ³n

### Workflow de Deployment
```
1. Desarrollo Local
   â†“
2. Commit y Push a branch feature/xxx
   â†“
3. Pull Request a develop
   â†“
4. Review y Tests AutomÃ¡ticos
   â†“
5. Merge a develop
   â†“
6. Deploy AutomÃ¡tico a Staging
   â†“
7. Testing Manual en Staging
   â†“
8. Pull Request de develop a main
   â†“
9. Review Final
   â†“
10. Merge a main
    â†“
11. Deploy AutomÃ¡tico a Production
```

### Deploy Manual

#### A Staging
```bash
# 1. Build local
docker build -t sales-datamart-api:staging .

# 2. Tag para registry
docker tag sales-datamart-api:staging username/sales-datamart-api:staging

# 3. Push
docker push username/sales-datamart-api:staging

# 4. Deploy en servidor
ssh user@staging-server
docker pull username/sales-datamart-api:staging
cd /opt/sales-api
docker-compose down
docker-compose up -d
```

#### A Production
```bash
# Similar a staging pero con tag 'latest'
docker build -t sales-datamart-api:latest .
docker tag sales-datamart-api:latest username/sales-datamart-api:latest
docker push username/sales-datamart-api:latest

# Deploy en servidor de producciÃ³n
ssh user@prod-server
docker pull username/sales-datamart-api:latest
cd /opt/sales-api
docker-compose down
docker-compose up -d
```

### Rollback

En caso de problemas en producciÃ³n:
```bash
# 1. Conectar al servidor
ssh user@prod-server

# 2. Ver tags disponibles
docker images username/sales-datamart-api

# 3. Detener contenedor actual
docker-compose down

# 4. Cambiar a versiÃ³n anterior
docker pull username/sales-datamart-api:previous-sha

# 5. Actualizar docker-compose.yml con tag anterior
vim docker-compose.yml
# Cambiar: image: username/sales-datamart-api:previous-sha

# 6. Reiniciar
docker-compose up -d

# 7. Verificar
curl http://localhost:8000/health
```

### Monitoreo Post-Deploy
```bash
# Ver logs en tiempo real
docker-compose logs -f api

# Health check
curl https://api.example.com/health

# MÃ©tricas
docker stats

# Ver versiÃ³n desplegada
curl https://api.example.com/ | jq .version
```

### Checklist de Deployment

#### Pre-Deploy

- [ ] Tests pasan localmente
- [ ] Cobertura >80%
- [ ] No hay secrets hardcodeados
- [ ] Variables de entorno configuradas
- [ ] DocumentaciÃ³n actualizada
- [ ] CHANGELOG.md actualizado

#### Durante Deploy

- [ ] Pipeline de CI/CD pasa
- [ ] Build de Docker exitoso
- [ ] Security scan sin issues crÃ­ticos
- [ ] Health check responde OK

#### Post-Deploy

- [ ] Endpoint `/health` responde correctamente
- [ ] Logs no muestran errores
- [ ] MÃ©tricas normales
- [ ] Tests de smoke pasan
- [ ] NotificaciÃ³n al equipo

---
## Autor
Danilo David Herazo Acevedo
Senior Python Developer

- Email: danilo.herazo@outlook.es
- GitHub: rangerOverHaul
- LinkedIn: https://www.linkedin.com/in/danilo-herazo-acevedo-0561281a9/
